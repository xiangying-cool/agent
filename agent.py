"""
ä¼ä¸šçº§æ”¿ç­–å’¨è¯¢æ™ºèƒ½ä½“æ ¸å¿ƒ
æ•´åˆåŒå±‚æ„å›¾è¯†åˆ«ã€æ··åˆæ£€ç´¢ã€å·¥å…·é“¾è®¡ç®—ã€å¤šAgentåä½œ
å¢å¼ºç‰ˆï¼šæ”¯æŒ BM25+å‘é‡åŒè·¯å¬å›ã€å®ä½“æŠ½å–ã€åæ€é“¾ã€å¤šæ™ºèƒ½ä½“
"""
from typing import List, Dict, Tuple, Optional
from knowledge_base import KnowledgeBase
from llm_client import LLMClient
from intent_recognition import IntentRecognizer, RejectionHandler
from tools import SubsidyCalculator, RecommendationEngine
from reranker import Reranker, HybridRetriever
from prompt_builder import PromptBuilder, OutputFormatter
import config
import time

# å¯é€‰å¢å¼ºæ¨¡å—
try:
    from ner_extractor import EntityExtractor
    NER_AVAILABLE = True
except ImportError:
    NER_AVAILABLE = False
    print("æç¤º: ner_extractor æœªæ‰¾åˆ°ï¼Œå®ä½“æŠ½å–ä¸å¯ç”¨")

try:
    from reflection import ReflectionAgent
    REFLECTION_AVAILABLE = True
except ImportError:
    REFLECTION_AVAILABLE = False
    print("æç¤º: reflection æœªæ‰¾åˆ°ï¼Œåæ€é“¾ä¸å¯ç”¨")

try:
    from multi_agent import MultiAgentOrchestrator
    MULTI_AGENT_AVAILABLE = True
except ImportError:
    MULTI_AGENT_AVAILABLE = False
    print("æç¤º: multi_agent æœªæ‰¾åˆ°ï¼Œå¤šæ™ºèƒ½ä½“åä½œä¸å¯ç”¨")

try:
    from plugin_manager import PluginManager
    PLUGIN_AVAILABLE = True
except ImportError:
    PLUGIN_AVAILABLE = False
    print("æç¤º: plugin_manager æœªæ‰¾åˆ°ï¼Œæ’ä»¶ç³»ç»Ÿä¸å¯ç”¨")

try:
    from cache_manager import CacheManager, cache_manager
    CACHE_AVAILABLE = True
except ImportError:
    CACHE_AVAILABLE = False
    cache_manager = None
    print("æç¤º: cache_manager æœªæ‰¾åˆ°ï¼Œç¼“å­˜åŠŸèƒ½ä¸å¯ç”¨")

# æ–°å¢å¢å¼ºæ¨¡å—
try:
    from monitor import monitoring_system
    MONITOR_AVAILABLE = True
except ImportError:
    MONITOR_AVAILABLE = False
    monitoring_system = None
    print("æç¤º: monitor æœªæ‰¾åˆ°ï¼Œç›‘æ§åŠŸèƒ½ä¸å¯ç”¨")

try:
    from feedback_system import feedback_system
    FEEDBACK_AVAILABLE = True
except ImportError:
    FEEDBACK_AVAILABLE = False
    feedback_system = None
    print("æç¤º: feedback_system æœªæ‰¾åˆ°ï¼Œåé¦ˆåŠŸèƒ½ä¸å¯ç”¨")

try:
    from urgency_detector import urgency_detector
    URGENCY_AVAILABLE = True
except ImportError:
    URGENCY_AVAILABLE = False
    urgency_detector = None
    print("æç¤º: urgency_detector æœªæ‰¾åˆ°ï¼Œç´§æ€¥åº¦è¯†åˆ«ä¸å¯ç”¨")

try:
    from quality_validator import quality_validator
    QUALITY_AVAILABLE = True
except ImportError:
    QUALITY_AVAILABLE = False
    quality_validator = None
    print("æç¤º: quality_validator æœªæ‰¾åˆ°ï¼Œè´¨é‡éªŒè¯ä¸å¯ç”¨")

try:
    from location_service import location_service
    LOCATION_AVAILABLE = True
except ImportError:
    LOCATION_AVAILABLE = False
    location_service = None
    print("æç¤º: location_service æœªæ‰¾åˆ°ï¼Œåœ°ç†ä½ç½®åŠŸèƒ½ä¸å¯ç”¨")

try:
    from emotion_intelligence import emotion_intelligence
    EMOTION_AVAILABLE = True
except ImportError:
    EMOTION_AVAILABLE = False
    emotion_intelligence = None
    print("æç¤º: emotion_intelligence æœªæ‰¾åˆ°ï¼Œæƒ…æ„Ÿæ™ºèƒ½ä¸å¯ç”¨")

try:
    from contradiction_detector import contradiction_detector
    CONTRADICTION_AVAILABLE = True
except ImportError:
    CONTRADICTION_AVAILABLE = False
    contradiction_detector = None
    print("æç¤º: contradiction_detector æœªæ‰¾åˆ°ï¼ŒçŸ›ç›¾æ£€æµ‹ä¸å¯ç”¨")

try:
    from policy_validator import policy_validator
    POLICY_VALIDATOR_AVAILABLE = True
except ImportError:
    POLICY_VALIDATOR_AVAILABLE = False
    policy_validator = None
    print("æç¤º: policy_validator æœªæ‰¾åˆ°ï¼Œæ”¿ç­–éªŒè¯ä¸å¯ç”¨")

try:
    from external_api_manager import external_api_manager
    EXTERNAL_API_AVAILABLE = True
except ImportError:
    EXTERNAL_API_AVAILABLE = False
    external_api_manager = None
    print("æç¤º: external_api_manager æœªæ‰¾åˆ°ï¼Œå¤–éƒ¨APIä¸å¯ç”¨")


class PolicyAgent:
    """ä¼ä¸šçº§æ”¿ç­–å’¨è¯¢æ™ºèƒ½ä½“"""
    
    def __init__(self, enable_advanced_features: bool = True):
        print("åˆå§‹åŒ–ä¼ä¸šçº§æ”¿ç­–å’¨è¯¢æ™ºèƒ½ä½“...")
        
        # æ ¸å¿ƒæ¨¡å—
        self.kb = KnowledgeBase()
        self.llm = LLMClient()
        
        # åŒå±‚æ„å›¾è¯†åˆ«
        self.intent_recognizer = IntentRecognizer()
        
        # å·¥å…·é“¾
        self.calculator = SubsidyCalculator()
        self.recommender = RecommendationEngine()
        
        # Reranker
        self.reranker = Reranker()
        self.hybrid_retriever = None  # åˆå§‹åŒ–åè®¾ç½®
        
        # Promptæ„é€ å’Œæ ¼å¼åŒ–
        self.prompt_builder = PromptBuilder()
        self.output_formatter = OutputFormatter()
        
        # å¢å¼ºæ¨¡å—ï¼ˆå¯é€‰ï¼‰
        self.enable_advanced = enable_advanced_features
        self.ner_extractor = EntityExtractor(self.llm) if NER_AVAILABLE and enable_advanced_features else None
        self.reflection_agent = ReflectionAgent(self.llm) if REFLECTION_AVAILABLE and enable_advanced_features else None
        self.multi_agent = None  # åœ¨ initialize ä¸­è®¾ç½®
        
        # æ’ä»¶ç³»ç»Ÿ
        self.plugin_manager = None
        if PLUGIN_AVAILABLE and enable_advanced_features:
            self.plugin_manager = PluginManager()
            self.plugin_manager.load_all_plugins()
        
        # ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = cache_manager if CACHE_AVAILABLE else None
        
        # æ–°å¢å¢å¼ºæ¨¡å—
        self.monitoring_system = monitoring_system if MONITOR_AVAILABLE else None
        self.feedback_system = feedback_system if FEEDBACK_AVAILABLE else None
        self.urgency_detector = urgency_detector if URGENCY_AVAILABLE else None
        self.quality_validator = quality_validator if QUALITY_AVAILABLE else None
        self.location_service = location_service if LOCATION_AVAILABLE else None
        self.emotion_intelligence = emotion_intelligence if EMOTION_AVAILABLE else None
        self.contradiction_detector = contradiction_detector if CONTRADICTION_AVAILABLE else None
        self.policy_validator = policy_validator if POLICY_VALIDATOR_AVAILABLE else None
        self.external_api = external_api_manager if EXTERNAL_API_AVAILABLE else None
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # æ€§èƒ½ç›‘æ§
        self.metrics = {
            "total_queries": 0,
            "successful_queries": 0,
            "rejected_queries": 0,
            "failed_queries": 0,
            "avg_latency": 0,
            "latency_history_ms": []
        }
    
    def initialize(self, force_rebuild: bool = False):
        """åˆå§‹åŒ–çŸ¥è¯†åº“å’Œæ··åˆæ£€ç´¢å™¨"""
        self.kb.build_knowledge_base(force_rebuild=force_rebuild)
        
        # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        if self.kb.vectorstore:
            self.hybrid_retriever = HybridRetriever(
                self.kb.vectorstore,
                self.reranker
            )
        
        print("æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ!")
        
        # åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“ç¼–æ’å™¨
        if MULTI_AGENT_AVAILABLE and self.enable_advanced:
            self.multi_agent = MultiAgentOrchestrator(self.kb, self.llm, self.calculator)
            print("âœ“ å¤šæ™ºèƒ½ä½“åä½œå·²å¯ç”¨")
    
    def query(self, question: str, return_sources: bool = True, user_location: Optional[Dict] = None) -> Dict:
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜ï¼ˆä¼ä¸šçº§æµç¨‹ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            return_sources: æ˜¯å¦è¿”å›æ£€ç´¢åˆ°çš„åŸæ–‡
            user_location: ç”¨æˆ·ä½ç½®ä¿¡æ¯ï¼Œæ ¼å¼: {"province": "å±±ä¸œçœ", "city": "æµå—å¸‚", "district": "å†ä¸‹åŒº"}
            
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        self.metrics["total_queries"] += 1
        
        # ========== æ–°å¢: åœ°ç†ä½ç½®å¤„ç† ==========
        if user_location and self.location_service:
            location_keywords = self.location_service.get_location_keywords(user_location)
            print(f"\nğŸ“ ç”¨æˆ·ä½ç½®: {user_location.get('city', '')} {user_location.get('district', '')}")
            print(f"   ä½ç½®å…³é”®è¯: {', '.join(location_keywords[:3])}")
        
        # ========== æ–°å¢: ç´§æ€¥ç¨‹åº¦è¯†åˆ« ==========
        urgency_info = None
        if self.urgency_detector:
            urgency_info = self.urgency_detector.detect(question)
            if urgency_info["fast_track"]:
                print(f"\nâš¡ æ£€æµ‹åˆ°ç´§æ€¥æŸ¥è¯¢ (P{urgency_info['priority']}): {urgency_info['level']}")
                print(f"   åŸå› : {', '.join(urgency_info['reasons'])}")
        
        # ========== æ–°å¢: æƒ…æ„Ÿæ™ºèƒ½åˆ†æ ==========
        emotion_analysis = None
        if self.emotion_intelligence:
            emotion_analysis = self.emotion_intelligence.analyze(question, urgency_info)
            if emotion_analysis["emotion"] != "neutral":
                print(f"\nğŸ’ æƒ…æ„ŸçŠ¶æ€: {emotion_analysis['user_state']}")
                print(f"   å»ºè®®è¯­æ°”: {emotion_analysis['recommended_tone']}")
        
        # ========== ç¼“å­˜æ£€æŸ¥ ==========
        if self.cache_manager:
            cached_result = self.cache_manager.get(question)
            if cached_result:
                # æ›´æ–°æŒ‡æ ‡
                self.metrics["successful_queries"] += 1
                latency = time.time() - start_time
                self.metrics["latency_history_ms"].append(latency * 1000)
                self._update_latency(latency)
                print(f"\nâœ“ ç¼“å­˜å‘½ä¸­ (è€—æ—¶: {latency:.2f}ç§’)")
                print(f"{'='*60}\n")
                return cached_result
        
        try:
            print(f"\n{'='*60}")
            print(f"ç”¨æˆ·é—®é¢˜: {question}")
            print(f"{'='*60}")
            
            # ========== æ­¥éª¤1: åŒå±‚æ„å›¾è¯†åˆ« ==========
            print("\n[1/5] æ„å›¾è¯†åˆ«...")
            intent_result = self.intent_recognizer.recognize(question)
            
            # å¦‚æœåº”è¯¥æ‹’ç»
            if intent_result["should_reject"]:
                self.metrics["rejected_queries"] += 1
                rejection_response = RejectionHandler.get_rejection_response(
                    intent_result["rejection_reason"]
                )
                return {
                    "answer": rejection_response,
                    "sources": [],
                    "confidence": 0.0,
                    "intent_type": None,
                    "rejected": True
                }
            
            intent_type = intent_result["intent_type"]
            print(f"âœ“ æ„å›¾ç±»å‹: {intent_type} ({config.INTENT_TYPES[intent_type]})")
            print(f"âœ“ ç½®ä¿¡åº¦: {intent_result['confidence']:.2%}")
            
            # ========== æ­¥éª¤2: ä»»åŠ¡è·¯ç”±ä¸æ‰§è¡Œ ==========
            print(f"\n[2/5] ä»»åŠ¡è·¯ç”±ä¸æ‰§è¡Œ...")
            
            if intent_type == "CALCULATION":
                result = self._handle_calculation(question)
            elif intent_type == "RECOMMENDATION":
                result = self._handle_recommendation(question)
            elif intent_type == "DATA_QUERY":
                result = self._handle_data_query(question, user_location=user_location)
            elif intent_type == "COMPLEX":
                result = self._handle_complex(question)
            else:  # POLICY_QA
                result = self._handle_policy_qa(question, user_location=user_location)
            
            # ========== æ­¥éª¤3: è¾“å‡ºæ ¼å¼åŒ– ==========
            print(f"\n[5/5] è¾“å‡ºæ ¼å¼åŒ–...")
            result["answer"] = self.output_formatter.format(
                result["answer"],
                metadata={
                    "sources": result.get("sources", []),
                    "confidence": result.get("confidence", 0.0)
                }
            )
            
            # ========== æ–°å¢: è´¨é‡éªŒè¯ ==========
            if self.quality_validator:
                validation_result = self.quality_validator.validate(
                    question,
                    result["answer"],
                    result.get("sources", [])
                )
                result["quality_score"] = validation_result["overall_score"]
                result["quality_passed"] = validation_result["passed"]
                
                # å¦‚æœè´¨é‡ä¸è¿‡å…³ï¼Œè®°å½•é—®é¢˜
                if not validation_result["passed"]:
                    print(f"\nâš ï¸ è´¨é‡éªŒè¯: {validation_result['overall_score']}/100 (ä¸è¿‡å…³)")
                    if validation_result["issues"]:
                        print(f"   é—®é¢˜: {validation_result['issues'][:2]}")
                else:
                    print(f"\nâœ… è´¨é‡éªŒè¯: {validation_result['overall_score']}/100 (é€šè¿‡)")
            
            # æ·»åŠ æ„å›¾ç±»å‹åˆ°ç»“æœ
            result["intent_type"] = intent_type
            result["rejected"] = False
            if urgency_info:
                result["urgency"] = urgency_info
            
            # ä¿å­˜å¯¹è¯å†å²
            self._save_conversation(question, result)
            
            # æ›´æ–°æŒ‡æ ‡
            self.metrics["successful_queries"] += 1
            latency = time.time() - start_time
            self.metrics["latency_history_ms"].append(latency * 1000)
            self._update_latency(latency)
            
            # ========== æ–°å¢: æ€§èƒ½ç›‘æ§ ==========
            if self.monitoring_system:
                self.monitoring_system.record_query({
                    "query": question,
                    "status": "success",
                    "latency_ms": latency * 1000,
                    "confidence": result.get("confidence", 0),
                })
            
            print(f"\nâœ“ æŸ¥è¯¢å®Œæˆ (è€—æ—¶: {latency:.2f}ç§’)")
            print(f"{'='*60}\n")
            
            # ========== ç¼“å­˜ç»“æœ ==========
            if self.cache_manager:
                # ç¼“å­˜å¸¸è§é—®é¢˜ç±»å‹çš„ç­”æ¡ˆï¼ˆæ”¿ç­–é—®ç­”ã€è®¡ç®—ã€æ¨èï¼‰
                if intent_type in ["POLICY_QA", "CALCULATION", "RECOMMENDATION"]:
                    self.cache_manager.set(question, result)
                    print(f"âœ“ ç»“æœå·²ç¼“å­˜")
            
            return result
            
        except Exception as e:
            print(f"\nâœ— æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.metrics["failed_queries"] += 1
            
            # ========== æ–°å¢: é”™è¯¯ç›‘æ§ ==========
            if self.monitoring_system:
                latency = time.time() - start_time
                self.monitoring_system.record_query({
                    "query": question,
                    "status": "error",
                    "latency_ms": latency * 1000,
                    "confidence": 0,
                    "error_msg": str(e)
                })
            
            return {
                "answer": "æŠ±æ­‰ï¼Œç³»ç»Ÿå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»äººå·¥å®¢æœã€‚",
                "sources": [],
                "confidence": 0.0,
                "intent_type": None,
                "rejected": False,
                "error": str(e)
            }
    
    def _handle_policy_qa(self, question: str, user_location: Optional[Dict] = None) -> Dict:
        """å¤„ç†æ”¿ç­–æ–‡æœ¬é—®ç­”"""
        print("æ‰§è¡Œ: æ”¿ç­–æ–‡æœ¬é—®ç­”")
        
        # æ··åˆæ£€ç´¢
        docs = self._retrieve_documents(question, user_location=user_location)
        if not docs:
            return self._no_result_response()
        
        # ========== æ–°å¢: æ”¿ç­–éªŒè¯ ==========
        if self.policy_validator and len(docs) > 0:
            policies_to_validate = []
            for doc in docs[:3]:  # éªŒè¯å‰3ä¸ª
                policies_to_validate.append({
                    "content": doc.page_content,
                    "source": doc.metadata.get('source', 'Unknown'),
                    "date": doc.metadata.get('date', '')
                })
            
            validation_result = self.policy_validator.batch_validate(policies_to_validate)
            stats = validation_result["statistics"]
            
            if stats["expired"] > 0 or stats["obsolete"] > 0:
                print(f"\nâš ï¸ æ”¿ç­–æ—¶æ•ˆæ€§æ£€æŸ¥: {stats['expired']}ä¸ªå·²è¿‡æœŸ, {stats['obsolete']}ä¸ªå·²åºŸæ­¢")
        
        # ========== æ–°å¢: çŸ›ç›¾æ£€æµ‹ ==========
        if self.contradiction_detector and len(docs) >= 2:
            policies_to_check = []
            for doc in docs[:5]:  # æ£€æŸ¥å‰5ä¸ª
                policies_to_check.append({
                    "content": doc.page_content,
                    "source": doc.metadata.get('source', 'Unknown'),
                    "date": doc.metadata.get('date', '')
                })
            
            contradiction_result = self.contradiction_detector.detect(policies_to_check)
            if contradiction_result["has_contradiction"]:
                print(f"\nâš ï¸ å‘ç° {len(contradiction_result['contradictions'])} ä¸ªæ”¿ç­–çŸ›ç›¾")
                print(f"   ä¸€è‡´æ€§åˆ†æ•°: {contradiction_result['consistency_score']:.2f}")
        
        # æ„å»ºPrompt
        messages = self.prompt_builder.build_policy_qa_prompt(question, docs)
        
        # LLMç”Ÿæˆ
        answer = self.llm.chat(messages)
        
        # æå–æ¥æº
        sources = [{
            "source": doc.metadata.get('source', 'Unknown'),
            "content": doc.page_content[:200],
            "similarity": 0.85  # ç®€åŒ–
        } for doc in docs]
        
        return {
            "answer": answer,
            "sources": sources,
            "confidence": 0.85
        }
    
    def _handle_calculation(self, question: str) -> Dict:
        """å¤„ç†è¡¥è´´è®¡ç®—"""
        print("æ‰§è¡Œ: è¡¥è´´ç²¾ç¡®è®¡ç®—")
        
        # æå–é‡‘é¢å’Œç±»å‹ï¼ˆç®€åŒ–å®ç°ï¼‰
        # å®é™…åº”ä½¿ç”¨NERæˆ–LLMæå–
        import re
        amounts = re.findall(r'(\d+)', question)
        
        if amounts:
            amount = float(amounts[0])
            # åˆ¤æ–­äº§å“ç±»å‹
            if "æ‰‹æœº" in question:
                calc_result = self.calculator.calculate_digital_subsidy("æ‰‹æœº", amount)
            else:
                calc_result = self.calculator.calculate_appliance_subsidy(amount)
            
            # æ„å»ºPrompt
            messages = self.prompt_builder.build_calculation_prompt(
                question, calc_result
            )
            
            # LLMè§£é‡Š
            answer = self.llm.chat(messages)
            
            return {
                "answer": answer,
                "sources": [],
                "confidence": 1.0,  # å·¥å…·è®¡ç®—ï¼Œ100%å‡†ç¡®
                "calculation": calc_result
            }
        else:
            # é‡‘é¢æœªæ˜ç¡®ï¼Œè½¬ä¸ºæ”¿ç­–é—®ç­”
            return self._handle_policy_qa(question)
    
    def _handle_recommendation(self, question: str) -> Dict:
        """å¤„ç†æ™ºèƒ½æ¨èï¼ˆä½¿ç”¨åŠ¨æ€è§„åˆ’å…¨å±€æœ€ä¼˜ï¼‰"""
        print("æ‰§è¡Œ: æ™ºèƒ½æ–¹æ¡ˆæ¨èï¼ˆåŠ¨æ€è§„åˆ’ï¼‰")
        
        # æå–é¢„ç®—å’Œéœ€æ±‚
        if self.ner_extractor:
            # ä½¿ç”¨ NER æå–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            entities = self.ner_extractor.extract(question)
            budget = entities.get("amounts", [10000])[0] if entities.get("amounts") else 10000
            needs = entities.get("products", [])
        else:
            # å›é€€åˆ°æ­£åˆ™æå–
            import re
            budgets = re.findall(r'(\d+)', question)
            budget = float(budgets[0]) if budgets else 10000
            
            # æå–éœ€æ±‚ï¼ˆåªåŒ¹é…å®šä¹‰çš„äº§å“åï¼‰
            product_keywords = ["å†°ç®±", "æ´—è¡£æœº", "ç”µè§†", "æ‰‹æœº", "å¹³æ¿", "ç©ºè°ƒ"]
            needs = []
            for product in product_keywords:
                if product in question:
                    needs.append(product)
        
        print(f"[DEBUG Agent] æå–é¢„ç®—: {budget}, éœ€æ±‚: {needs}")
        
        # è°ƒç”¨åŠ¨æ€è§„åˆ’æ¨èï¼ˆå…¨å±€æœ€ä¼˜ï¼‰
        recommendation = self.recommender.recommend_max_subsidy_plan(
            budget, 
            needs if needs else None,
            algorithm="dp"  # ä½¿ç”¨åŠ¨æ€è§„åˆ’
        )
        
        print(f"[DEBUG Agent] æ¨èç»“æœ: {len(recommendation.get('selected_products', []))}ä»¶äº§å“, æ€»è¡¥è´´ï¿¥{recommendation.get('total_subsidy', 0)}")
        
        # è°ƒç”¨ä»·æ ¼æ¯”è¾ƒæ’ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        price_comparison = None
        if self.plugin_manager and "price_comparator" in self.plugin_manager.get_available_plugins():
            try:
                products = [p["name"] for p in recommendation.get("selected_products", [])]
                if products:
                    price_comparison = self.plugin_manager.execute_plugin(
                        "price_comparator",
                        {"products": products, "budget": budget}
                    )
                    print(f"âœ“ ä»·æ ¼æ¯”è¾ƒæ’ä»¶è¿è¡ŒæˆåŠŸ: æ€»èŠ‚çœï¿¥{price_comparison.get('total_savings', 0)}")
            except Exception as e:
                print(f"âš  ä»·æ ¼æ¯”è¾ƒæ’ä»¶æ‰§è¡Œå¤±è´¥: {e}")
        
        # æ„å»º Prompt
        messages = self.prompt_builder.build_recommendation_prompt(
            question, recommendation
        )
        
        # LLM ç”Ÿæˆæ¨èè¯´æ˜
        answer = self.llm.chat(messages)
        
        return {
            "answer": answer,
            "sources": [],
            "confidence": 0.95,  # å…¨å±€æœ€ä¼˜ç½®ä¿¡åº¦æ›´é«˜
            "recommendation": recommendation,
            "algorithm": "dp",
            "is_optimal": recommendation.get("is_optimal", True),
            "price_comparison": price_comparison  # æ·»åŠ ä»·æ ¼æ¯”è¾ƒç»“æœ
        }
    
    def _handle_data_query(self, question: str, user_location: Optional[Dict] = None) -> Dict:
        """å¤„ç†æ•°æ®/å‹å·æŸ¥è¯¢"""
        print("æ‰§è¡Œ: æ•°æ®æŸ¥è¯¢")
        # ç®€åŒ–ï¼šè½¬ä¸ºæ”¿ç­–é—®ç­”
        return self._handle_policy_qa(question, user_location=user_location)
    
    def _handle_complex(self, question: str) -> Dict:
        """å¤„ç†å¤æ‚ç»¼åˆé—®é¢˜"""
        print("æ‰§è¡Œ: å¤æ‚ç»¼åˆåˆ†æ")
        # ç®€åŒ–ï¼šä½¿ç”¨å¢å¼ºæ£€ç´¢
        docs = self._retrieve_documents(question, top_k=config.RERANK_TOP_K)
        
        # å¤šæºä¸Šä¸‹æ–‡
        multi_source = {"ç»¼åˆæ”¿ç­–": docs}
        
        messages = self.prompt_builder.build_complex_prompt(
            question, multi_source
        )
        
        answer = self.llm.chat(messages)
        
        sources = [{
            "source": doc.metadata.get('source', 'Unknown'),
            "content": doc.page_content[:200],
            "similarity": 0.80
        } for doc in docs[:3]]
        
        return {
            "answer": answer,
            "sources": sources,
            "confidence": 0.75
        }
    
    def _retrieve_documents(self, query: str, top_k: int = None, user_location: Optional[Dict] = None) -> List:
        """æ£€ç´¢æ–‡æ¡£(ä¼˜åŒ–ç‰ˆ:å¹¶è¡Œæ£€ç´¢+æ™ºèƒ½ç¼“å­˜)"""
        print(f"[3/5] æ··åˆæ£€ç´¢...")
        
        if top_k is None:
            top_k = config.RERANK_TOP_K
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"docs:{query}:{top_k}:{user_location.get('city') if user_location else 'none'}"
        
        # å°è¯•ä»ç¼“å­˜è·å–
        if self.cache_manager:
            cached_docs = self.cache_manager.get(cache_key)
            if cached_docs:
                print(f"âœ“ æ–‡æ¡£ç¼“å­˜å‘½ä¸­")
                return cached_docs
        
        # å¹¶è¡Œæ£€ç´¢
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # åŒæ—¶è¿›è¡Œå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢
            if self.hybrid_retriever:
                future = executor.submit(self.hybrid_retriever.retrieve, query, top_k)
                docs = future.result(timeout=3.0)  # 3ç§’è¶…æ—¶
            else:
                future = executor.submit(self.kb.search, query, top_k)
                docs = future.result(timeout=3.0)
        
        # ========== æ–°å¢: åŸºäºåœ°ç†ä½ç½®é‡æ’ ==========
        if user_location and self.location_service and docs:
            # å°†æ–‡æ¡£è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            doc_dicts = []
            for doc in docs:
                doc_dicts.append({
                    "content": doc.page_content,
                    "source": doc.metadata.get('source', 'Unknown'),
                    "score": 0.7,
                    "original_doc": doc
                })
            
            # åŸºäºä½ç½®é‡æ’
            reranked_dicts = self.location_service.rerank_by_location(
                doc_dicts,
                user_location,
                location_weight=0.3
            )
            
            # è½¬æ¢å›åŸå§‹æ ¼å¼
            docs = [d["original_doc"] for d in reranked_dicts]
            
            print(f"âœ“ åŸºäºä½ç½®é‡æ’åºå®Œæˆ (æƒé‡: 0.3)")
        
        # ç¼“å­˜ç»“æœ(5åˆ†é’ŸTTL)
        if self.cache_manager and docs:
            self.cache_manager.set(cache_key, docs, ttl=300)
        
        print(f"âœ“ æ£€ç´¢åˆ° {len(docs)} æ¡ç›¸å…³æ–‡æ¡£")
        return docs
    
    def _no_result_response(self) -> Dict:
        """æ— ç»“æœå“åº”"""
        return {
            "answer": "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ”¿ç­–ä¿¡æ¯ã€‚è¯·æ‚¨æ¢ä¸ªæ–¹å¼æé—®æˆ–è”ç³»äººå·¥å®¢æœã€‚",
            "sources": [],
            "confidence": 0.0
        }
    
    def _save_conversation(self, question: str, result: Dict):
        """ä¿å­˜å¯¹è¯å†å²"""
        self.conversation_history.append({
            "question": question,
            "answer": result.get("answer"),
            "intent_type": result.get("intent_type"),
            "confidence": result.get("confidence"),
            "timestamp": time.time()
        })
    
    def _update_latency(self, latency: float):
        """æ›´æ–°å¹³å‡å»¶è¿Ÿ"""
        total = self.metrics["total_queries"]
        current_avg = self.metrics["avg_latency"]
        self.metrics["avg_latency"] = (
            (current_avg * (total - 1) + latency) / total
        )
    
    def batch_query(self, questions: List[str]) -> List[Dict]:
        """æ‰¹é‡å¤„ç†é—®é¢˜(ä¼˜åŒ–ç‰ˆ:å¹¶è¡Œå¤„ç†)"""
        import concurrent.futures
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_question = {
                executor.submit(self.query, question, True): question 
                for question in questions
            }
            
            # æŒ‰é¡ºåºæ”¶é›†ç»“æœ
            for question in questions:
                for future, q in future_to_question.items():
                    if q == question:
                        try:
                            result = future.result(timeout=10.0)  # 10ç§’è¶…æ—¶
                            results.append(result)
                        except Exception as e:
                            results.append({
                                "answer": f"å¤„ç†å¤±è´¥: {str(e)}",
                                "sources": [],
                                "confidence": 0.0
                            })
                        break
        
        return results
    
    def evaluate(self, cases: List[Dict]) -> Dict:
        """æ‰¹é‡è¯„æµ‹ï¼šæ ¹æ®æœŸæœ›å…³é”®è¯ç²—ç•¥è®¡ç®—å‡†ç¡®ç‡ä¸å“åº”æ—¶é—´"""
        total = len(cases)
        correct = 0
        results = []
        latencies = []
        for case in cases:
            q = case.get("question", "")
            expected = case.get("expected_keywords", [])
            start = time.time()
            r = self.query(q, return_sources=True)
            lat_ms = (time.time() - start) * 1000
            latencies.append(lat_ms)
            ans = (r.get("answer") or "")
            ok = False
            ans_low = ans.lower()
            for kw in expected:
                if kw and kw.lower() in ans_low:
                    ok = True
                    break
            correct += (1 if ok else 0)
            results.append({
                "question": q,
                "ok": ok,
                "latency_ms": lat_ms,
                "confidence": r.get("confidence", 0),
                "answer": ans
            })
        accuracy = (correct / max(total, 1))
        avg_latency_ms = (sum(latencies) / len(latencies)) if latencies else 0
        return {"accuracy": accuracy, "avg_latency_ms": avg_latency_ms, "total": total, "correct": correct, "results": results}
    
    def get_conversation_history(self) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
    
    def get_metrics(self) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        sessions = self.metrics["total_queries"]
        hist = self.metrics.get("latency_history_ms", [])
        avg_ms = (sum(hist) / len(hist)) if hist else 0
        p95_ms = (sorted(hist)[max(int(len(hist) * 0.95) - 1, 0)] if hist else 0)
        error_rate = (self.metrics["failed_queries"] / max(sessions, 1))
        return {
            "sessions": sessions,
            "avg_latency_ms": avg_ms,
            "p95_latency_ms": p95_ms,
            "success_rate": (
                self.metrics["successful_queries"] /
                max(self.metrics["total_queries"], 1)
            ),
            "rejection_rate": (
                self.metrics["rejected_queries"] /
                max(self.metrics["total_queries"], 1)
            ),
            "error_rate": error_rate,
            "total_queries": self.metrics["total_queries"],
            "successful_queries": self.metrics["successful_queries"],
            "rejected_queries": self.metrics["rejected_queries"],
            "avg_latency": self.metrics["avg_latency"]
        }


if __name__ == "__main__":
    # æµ‹è¯•ä¼ä¸šçº§æ™ºèƒ½ä½“
    agent = PolicyAgent()
    agent.initialize(force_rebuild=False)
    
    # æµ‹è¯•é—®é¢˜ï¼ˆè¦†ç›–æ‰€æœ‰æ„å›¾ç±»å‹ï¼‰
    test_questions = [
        # POLICY_QA
        "æµå—å¸‚å®¶ç”µä»¥æ—§æ¢æ–°è¡¥è´´æ ‡å‡†æ˜¯å¤šå°‘ï¼Ÿ",
        
        # CALCULATION
        "ä¹°3000å…ƒä¹°ä¸ªå†°ç®±èƒ½è¡¥è´´å¤šå°‘é’±ï¼Ÿ",
        
        # RECOMMENDATION  
        "æˆ‘æœ‰15000å…ƒé¢„ç®—ï¼Œæ¨èä¸€ä¸ªæœ€åˆ’ç®—çš„æ¢æ–°æ–¹æ¡ˆ",
        
        # DATA_QUERY
        "æ‰‹æœºè´­æ–°è¡¥è´´å¦‚ä½•ç”³è¯·ï¼Ÿ",
        
        # COMPLEX
        "å®¶ç”µå’Œæ•°ç äº§å“çš„ä»¥æ—§æ¢æ–°æ”¿ç­–æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        
        # æ— å…³é—®é¢˜ï¼ˆåº”è¢«æ‹’ç»ï¼‰
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
    ]
    
    print("\n" + "="*80)
    print("ä¼ä¸šçº§æ”¿ç­–å’¨è¯¢æ™ºèƒ½ä½“ - ç³»ç»Ÿæµ‹è¯•")
    print("="*80)
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n\n{'#'*80}")
        print(f"æµ‹è¯•ç”¨ä¾‹ {i}/{len(test_questions)}")
        print(f"{'#'*80}")
        
        result = agent.query(question, return_sources=True)
        
        # è¾“å‡ºç»“æœ
        print(f"\n\nã€æœ€ç»ˆå›ç­”ã€‘")
        print(result['answer'])
        
        # å¦‚æœæ˜¯æ¨èï¼Œæ˜¾ç¤ºè¯¦ç»†æ–¹æ¡ˆ
        if result.get('recommendation'):
            rec = result['recommendation']
            print(f"\nã€æ¨èè¯¦æƒ…ã€‘")
            if 'selected_products' in rec:
                print(f"é€‰ä¸­äº§å“ï¼š{len(rec['selected_products'])}ä»¶")
                for p in rec['selected_products']:
                    print(f"  â€¢ {p['name']}ï¼ˆï¿¥{p['price']}ï¼‰â†’ è¡¥è´´ï¿¥{p['subsidy']}")
                print(f"æ€»è¡¥è´´ï¼šï¿¥{rec['total_subsidy']}ï¼Œå®ä»˜ï¼šï¿¥{rec['final_cost']}")
                print(f"èµ„é‡‘åˆ©ç”¨ç‡ï¼š{rec['utilization_rate']:.1%}")
                print(f"ç®—æ³•ï¼š{result.get('algorithm', 'N/A')}ï¼Œå…¨å±€æœ€ä¼˜ï¼š{result.get('is_optimal', False)}")
        
        if result.get('sources'):
            print(f"\nã€å‚è€ƒæ¥æºã€‘")
            for j, source in enumerate(result['sources'][:2], 1):
                print(f"{j}. {source['source']} (ç›¸å…³åº¦: {source.get('similarity', 0):.2%})")
    
    # è¾“å‡ºæ€§èƒ½æŒ‡æ ‡
    print(f"\n\n{'='*80}")
    print("æ€§èƒ½æŒ‡æ ‡")
    print("="*80)
    metrics = agent.get_metrics()
    print(f"æ€»æŸ¥è¯¢æ•°: {metrics['total_queries']}")
    print(f"æˆåŠŸæŸ¥è¯¢: {metrics['successful_queries']}")
    print(f"è¢«æ‹’ç»æŸ¥è¯¢: {metrics['rejected_queries']}")
    print(f"æˆåŠŸç‡: {metrics['success_rate']:.2%}")
    print(f"å¹³å‡å»¶è¿Ÿ: {metrics['avg_latency']:.2f}ç§’")
    print("="*80)
