"""
ç›‘æ§å‘Šè­¦ç³»ç»Ÿ - å®æ—¶è¿è¡ŒçŠ¶æ€ç›‘æ§ä¸æ™ºèƒ½å‘Šè­¦
"""
import time
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from collections import deque
import config


class MonitoringSystem:
    """ç³»ç»Ÿç›‘æ§ä¸å‘Šè­¦"""
    
    def __init__(self):
        self.metrics_history = deque(maxlen=1000)  # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
        self.alert_records = []
        self.metrics_file = os.path.join(config.LOG_DIR, "metrics.json")
        self.alert_file = os.path.join(config.LOG_DIR, "alerts.json")
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(config.LOG_DIR, exist_ok=True)
        
        # å‘Šè­¦é˜ˆå€¼é…ç½®
        self.thresholds = {
            "error_rate": config.ALERT_THRESHOLD.get("error_rate", 0.05),
            "latency_ms": config.ALERT_THRESHOLD.get("latency_ms", 5000),
            "max_queue_size": 100,
            "min_success_rate": 0.90
        }
    
    def record_query(self, query_data: Dict):
        """
        è®°å½•å•æ¬¡æŸ¥è¯¢çš„æ€§èƒ½æŒ‡æ ‡
        
        Args:
            query_data: {
                "query": "ç”¨æˆ·é—®é¢˜",
                "status": "success/error",
                "latency_ms": å“åº”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰,
                "confidence": ç½®ä¿¡åº¦,
                "error_msg": é”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            }
        """
        metric = {
            "timestamp": datetime.now().isoformat(),
            "query": query_data.get("query", "")[:100],  # åªè®°å½•å‰100å­—ç¬¦
            "status": query_data.get("status", "unknown"),
            "latency_ms": query_data.get("latency_ms", 0),
            "confidence": query_data.get("confidence", 0),
            "error_msg": query_data.get("error_msg", "")
        }
        
        self.metrics_history.append(metric)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
        self._check_alerts(metric)
    
    def _check_alerts(self, current_metric: Dict):
        """æ£€æŸ¥æ˜¯å¦è§¦å‘å‘Šè­¦"""
        alerts = []
        
        # 1. å»¶è¿Ÿå‘Šè­¦
        if current_metric["latency_ms"] > self.thresholds["latency_ms"]:
            alerts.append({
                "level": "WARNING",
                "type": "HIGH_LATENCY",
                "message": f"å“åº”æ—¶é—´è¿‡é•¿: {current_metric['latency_ms']}ms (é˜ˆå€¼: {self.thresholds['latency_ms']}ms)",
                "metric": current_metric
            })
        
        # 2. é”™è¯¯ç‡å‘Šè­¦ï¼ˆè®¡ç®—æœ€è¿‘50æ¬¡è¯·æ±‚ï¼‰
        if len(self.metrics_history) >= 50:
            recent_50 = list(self.metrics_history)[-50:]
            error_count = sum(1 for m in recent_50 if m["status"] == "error")
            error_rate = error_count / 50
            
            if error_rate > self.thresholds["error_rate"]:
                alerts.append({
                    "level": "CRITICAL",
                    "type": "HIGH_ERROR_RATE",
                    "message": f"é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%} (é˜ˆå€¼: {self.thresholds['error_rate']:.2%})",
                    "detail": f"æœ€è¿‘50æ¬¡è¯·æ±‚ä¸­æœ‰{error_count}æ¬¡å¤±è´¥"
                })
        
        # 3. ç½®ä¿¡åº¦å‘Šè­¦
        if current_metric["status"] == "success" and current_metric["confidence"] < 0.5:
            alerts.append({
                "level": "INFO",
                "type": "LOW_CONFIDENCE",
                "message": f"å›ç­”ç½®ä¿¡åº¦è¾ƒä½: {current_metric['confidence']:.2%}",
                "query": current_metric["query"]
            })
        
        # è®°å½•å‘Šè­¦
        for alert in alerts:
            self._save_alert(alert)
    
    def _save_alert(self, alert: Dict):
        """ä¿å­˜å‘Šè­¦è®°å½•"""
        alert["timestamp"] = datetime.now().isoformat()
        self.alert_records.append(alert)
        
        # æ‰“å°å‘Šè­¦
        level_emoji = {
            "INFO": "â„¹ï¸",
            "WARNING": "âš ï¸",
            "CRITICAL": "ğŸš¨"
        }
        emoji = level_emoji.get(alert["level"], "ğŸ“¢")
        print(f"{emoji} [{alert['level']}] {alert['type']}: {alert['message']}")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(self.alert_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(alert, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"å‘Šè­¦ä¿å­˜å¤±è´¥: {e}")
    
    def get_statistics(self, minutes: int = 60) -> Dict:
        """
        è·å–ç»Ÿè®¡æ•°æ®
        
        Args:
            minutes: ç»Ÿè®¡æœ€è¿‘Nåˆ†é’Ÿçš„æ•°æ®
        
        Returns:
            ç»Ÿè®¡æŠ¥å‘Š
        """
        if not self.metrics_history:
            return {"message": "æš‚æ— æ•°æ®"}
        
        # ç­›é€‰æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        recent_metrics = [
            m for m in self.metrics_history
            if datetime.fromisoformat(m["timestamp"]) > cutoff_time
        ]
        
        if not recent_metrics:
            return {"message": f"æœ€è¿‘{minutes}åˆ†é’Ÿæ— æ•°æ®"}
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        total = len(recent_metrics)
        success_count = sum(1 for m in recent_metrics if m["status"] == "success")
        error_count = sum(1 for m in recent_metrics if m["status"] == "error")
        
        latencies = [m["latency_ms"] for m in recent_metrics]
        avg_latency = sum(latencies) / len(latencies) if latencies else 0
        max_latency = max(latencies) if latencies else 0
        
        confidences = [m["confidence"] for m in recent_metrics if m["confidence"] > 0]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        return {
            "time_range": f"æœ€è¿‘{minutes}åˆ†é’Ÿ",
            "total_requests": total,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate": f"{(success_count / total * 100):.2f}%",
            "error_rate": f"{(error_count / total * 100):.2f}%",
            "avg_latency_ms": round(avg_latency, 2),
            "max_latency_ms": max_latency,
            "avg_confidence": f"{(avg_confidence * 100):.2f}%",
            "status": "æ­£å¸¸" if error_count / total < self.thresholds["error_rate"] else "å¼‚å¸¸"
        }
    
    def get_recent_alerts(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„å‘Šè­¦è®°å½•"""
        return self.alert_records[-limit:]
    
    def export_metrics(self):
        """å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            with open(self.metrics_file, "w", encoding="utf-8") as f:
                json.dump(list(self.metrics_history), f, ensure_ascii=False, indent=2)
            print(f"âœ“ æ€§èƒ½æŒ‡æ ‡å·²å¯¼å‡ºåˆ°: {self.metrics_file}")
        except Exception as e:
            print(f"å¯¼å‡ºå¤±è´¥: {e}")


# å…¨å±€ç›‘æ§å®ä¾‹
monitoring_system = MonitoringSystem() if config.ENABLE_MONITORING else None


if __name__ == "__main__":
    # æµ‹è¯•ç›‘æ§ç³»ç»Ÿ
    monitor = MonitoringSystem()
    
    print("=" * 60)
    print("ç›‘æ§ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿä¸€äº›æŸ¥è¯¢è®°å½•
    import random
    
    for i in range(100):
        status = "success" if random.random() > 0.1 else "error"
        monitor.record_query({
            "query": f"æµ‹è¯•æŸ¥è¯¢{i}",
            "status": status,
            "latency_ms": random.randint(500, 8000),
            "confidence": random.random(),
            "error_msg": "æµ‹è¯•é”™è¯¯" if status == "error" else ""
        })
    
    # æŸ¥çœ‹ç»Ÿè®¡
    print("\nç»Ÿè®¡æŠ¥å‘Š:")
    stats = monitor.get_statistics(minutes=60)
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # æŸ¥çœ‹å‘Šè­¦
    print("\næœ€è¿‘å‘Šè­¦:")
    alerts = monitor.get_recent_alerts(5)
    for alert in alerts:
        print(f"  [{alert['level']}] {alert['message']}")
    
    # å¯¼å‡ºæ•°æ®
    monitor.export_metrics()
